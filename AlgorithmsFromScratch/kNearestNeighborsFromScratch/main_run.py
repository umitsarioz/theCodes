#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""datascience_hw2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t_Sx8YH78QT47ziGbArVckX26xYt62Fp
"""

from sklearn import datasets # used for load iris dataset
from sklearn.model_selection import train_test_split # used for split our dataset train-test (70% - 30%)
from sklearn.metrics import accuracy_score # used for get accuracy
import numpy as np # used for array operations: shape,concatenate,expand_dims,square-root and substraction

dataset = datasets.load_iris() # load iris dataset

dataset # let's look the dataset

dataset.keys() # let's look keys of the dataset to decide what columns i need

# After examine dataset and dataset keys , i am taking needed columns 
X = dataset.data
y = dataset.target
features = dataset.feature_names
targets = dataset.target_names

# I'm looking my related columns
def giveInfo(X,y):
  print(f"Our feature values:{X}",
      f"\nOur Target values:{y}")
giveInfo(X,y)

# I should merge two column -> (our feature values and target values) For that target values array dimension is 1 but feature values dims are 2 . So i should expand dims to target_values
y_2d = np.expand_dims(y,axis=1) # convert y to 2dimension array.
X = np.concatenate((X,y_2d),axis=1)
giveInfo(X,y) # I check new feature values.

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=78) #I split our data %70 train , 30% test

# Let's chek shapes
print("Shape X:",X.shape,
      f"\n30% : {X.shape[0]*0.3}",
      "\n\nShape X_train:",X_train.shape,
      "\nShape X_test:",X_test.shape,
      "\nShape y",y.shape,
      "\nShape y_train:",y_train.shape,
      "\nShape y_test:",y_test.shape)

# Let's check our features,targets and their values 
print("Points' feature names:",features,
      "\nFirst point's feature values:",X_train[0],
      "\nFirst point's target value:",y_train[0],
      "\nFirst point's target name:",targets[y_train[0]])

# Everything is fine until now. I will use euclidean distance formula to calculate distances between points
def euclideanDistance(points1,points2):
  '''
  Formula : dist = square root ( subtracting of two point coordinate ^2).
  Input : points1 : coordinates of the point is in our dataset.
          points2 : coordinates of our point will be predicted. 
  Output : return distance is between points1 and points2
  '''
  distance = 0.0
  for i in range(len(points1) - 1 ): # we should substrac 1 . cuz last value is target value
    distance += (points1[i] - points2[i])**2 # (x1_i-x2_i)^2 
  dist = np.sqrt(distance)
  return dist

# I calculate distances and points then return all distances and points as a list.
def getPointsAndDistances(y,y_hat):
  '''
  Inputs : y -> our dataset 
           y_hat -> it's point will be predicted belong which class.
  Output : return all distances and with related points. 
  '''
  distances = list() # to store our distances
  for point in y:
    distance = euclideanDistance(point,y_hat) #calculate euc.distance 
    distances.append((point,distance)) #save points and the distance
  return distances
# I find nearest neighbors depending the distances list values
def findNearestNeighbors(pointsAndDistances,all_k):
  '''
  Inputs : pointsAndDistances -> All points and calculated distances with points values
           all_k -> Neighbors count
  Output : Return nearest neighbors values
  '''
  neighbors = list()
  pointsAndDistances.sort(key = lambda d : d[1]) #sort list by second element(second element is distances) .
  for k in range(all_k): #show our neighbors
    neighbors.append(pointsAndDistances[k][0]) # I added all neighbors ,and also target value of the neighbor.
  return neighbors

# for prediction ..
def toPredict(class_names,neighbors):
  '''
  Inputs : class_names : all class values
           neighbors : all neighbors

  Output : return max count of neighbors class(target values)
  '''
  ## Initialize count of all class values
  class_counts  = dict.fromkeys((class_names),0)

  #Initialize prediction point's class counts.
  prediction_class_counts = class_counts
  #Let's calculate class count of prediction point
  for c in neighbors: # Choose neighbors
    if c[-1] in prediction_class_counts.keys(): # If neighbors class exist prediction class. Then add +1.
      prediction_class_counts[c[-1]] +=1 
  most = max(prediction_class_counts.values()) # Find maximum count of classes. 
  prediction = list(prediction_class_counts.values()).index(most) # Find class that belong which class.
  
  return prediction

# All functions is prepared to use . Define knn and then run.
def knn(train,test,num_neighbors):
  '''
  Inputs: train -> train examples
          test -> test examples : points will be predicted belong which class
          num_Neighbors : count of neighbors
  Output: return all predictions of test set
  '''
  classes = dataset.target # all class values : in our dataset are [0,1,2]
  predictions = list() # to store predictions
  for prediction in test: # for test dataset , run all points
    distances = getPointsAndDistances(train,prediction) # calculate distance
    neighbors = findNearestNeighbors(distances,num_neighbors) # find nearest neighbors
    y_hat = toPredict(classes,neighbors) # to predict
    predictions.append(y_hat) # store prediction value in prediction list
  return predictions

# Show results 
def predictAndFindAccuracy(k):
  '''
  k is count of neighbors.
  '''
  predictions = knn(X_train,X_test,k) # run knn function
  print(f"knn is running for k = {k}") 
  wrong_prediction_count = 0
  for i in range(len(predictions)): # show all predictions
    if predictions[i] != y_test[i]:
      print(f"!!! {i}.prediction is WRONG -> Prediction:{predictions[i]},Real:{y_test[i]}")
      wrong_prediction_count += 1
    #else:
     # print(f"Prediction:{predictions[i]},Real:{y_test[i]}")
  scores = accuracy_score(y_test,predictions) # calculate accuracy using with scikitlearn lib.
  print(f"k = {k} \t\t\t Wrong Prediction Count : {wrong_prediction_count} \nAccuracy: {scores:.4f} \t Total prediction:{len(predictions)}\n\n\t\t********\n")
  return scores
predictAndFindAccuracy(1)
predictAndFindAccuracy(3)
predictAndFindAccuracy(5)
predictAndFindAccuracy(y_test.shape[0])

#for i in range(y_test.shape[0]):
# predictAndFindAccuracy(i)

'''
Observations:
If k is too small accuracy is low because of overfitting. Model is memorize.
If k is too large accuracy is decrease again because our model is too simple.
'''

